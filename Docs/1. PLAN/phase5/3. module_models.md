# ğŸ“ Docs/Plan/Phase5/module_models.md

---

## ğŸ“Œ ëª©ì 
- **Models ëª¨ë“ˆ**ì€ AI/ML í•™ìŠµ, ì‹ í˜¸ ìƒì„±, ëª¨ë¸ ì €ì¥ ë° í‰ê°€ì™€ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- ê°•í™”í•™ìŠµ, LSTM/GRU, ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ë“± ë‹¤ì–‘í•œ í•™ìŠµ ë°©ì‹ì„ ì§€ì›í•˜ë©°, ì§€ì†ì ì¸ í•™ìŠµê³¼ ì €ì¥ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“ ë””ë ‰í„°ë¦¬ êµ¬ì¡°
```plaintext
models/
â”œâ”€â”€ __init__.py              # ëª¨ë“ˆ ì´ˆê¸°í™” íŒŒì¼
â”œâ”€â”€ trainer.py               # ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ
â”œâ”€â”€ inference.py             # í•™ìŠµëœ ëª¨ë¸ ê¸°ë°˜ ì‹ í˜¸ ì˜ˆì¸¡
â”œâ”€â”€ evaluators.py            # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
â”œâ”€â”€ arbitrage_trainer.py     # ì•„ë¹„íŠ¸ë¼ì§€ ëª¨ë¸ í•™ìŠµ
â”œâ”€â”€ rl_trainer.py            # ê°•í™”í•™ìŠµ ëª¨ë¸ í•™ìŠµ
â”œâ”€â”€ auto_update.py           # ì§€ì†ì  í•™ìŠµ
â””â”€â”€ model_storage.py         # ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°
```
âœ¨ ì£¼ìš” ê¸°ëŠ¥
1ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ í•™ìŠµ (trainer.py)

ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë¡œì§ êµ¬í˜„.
ë°ì´í„° ì „ì²˜ë¦¬ì™€ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì œê³µ.
2ï¸âƒ£ ì‹ í˜¸ ì˜ˆì¸¡ (inference.py)

í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ í˜¸ ìƒì„±.
ëª¨ë¸ ê¸°ë°˜ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°˜í™˜.
3ï¸âƒ£ ëª¨ë¸ í‰ê°€ (evaluators.py)

í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€.
Precision, Recall, F1-score, Sharpe Ratio ë“±ì˜ ì§€í‘œ ì œê³µ.
4ï¸âƒ£ ì•„ë¹„íŠ¸ë¼ì§€ ëª¨ë¸ í•™ìŠµ (arbitrage_trainer.py)

ê±°ë˜ì†Œ ê°„ ê°€ê²© ì°¨ì´ë¥¼ í•™ìŠµí•˜ì—¬ ì•„ë¹„íŠ¸ë¼ì§€ ê¸°íšŒë¥¼ íƒì§€í•˜ëŠ” ëª¨ë¸ êµ¬í˜„.
5ï¸âƒ£ ê°•í™”í•™ìŠµ ëª¨ë¸ í•™ìŠµ (rl_trainer.py)

ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜(PPO, DDPG ë“±)ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ë§¤ë§¤ ì •ì±… í•™ìŠµ.
6ï¸âƒ£ ì§€ì†ì  í•™ìŠµ (auto_update.py)

ì§€ì†ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³  ëª¨ë¸ì„ ì—…ë°ì´íŠ¸.
7ï¸âƒ£ ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° (model_storage.py)

í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•˜ê³ , í•„ìš”í•œ ì‹œì ì— ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥ ì œê³µ.
ğŸ“„ ì£¼ìš” íŒŒì¼ ì„¤ëª…
1ï¸âƒ£ trainer.py
ëª©ì 
ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ë¡œì§ êµ¬í˜„.
ì£¼ìš” ê¸°ëŠ¥
ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬.
í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•.
ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì €ì¥.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def train_model(data, model_type):
    """
    ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
    :param data: í•™ìŠµ ë°ì´í„°
    :param model_type: í•™ìŠµí•  ëª¨ë¸ì˜ ìœ í˜• (e.g., "xgboost", "lstm")
    :return: í•™ìŠµëœ ëª¨ë¸ ê°ì²´
    """
    if model_type == "xgboost":
        model = XGBClassifier()
    elif model_type == "lstm":
        # LSTM í•™ìŠµ ë¡œì§ êµ¬í˜„
        pass
    else:
        raise ValueError("Unsupported model type")
    model.fit(data["features"], data["labels"])
    return model
2ï¸âƒ£ inference.py
ëª©ì 
í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•´ ì‹ í˜¸ ì˜ˆì¸¡.
ì£¼ìš” ê¸°ëŠ¥
ì…ë ¥ ë°ì´í„° ê¸°ë°˜ ì‹ í˜¸ ìƒì„±.
ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def predict_signal(model, input_data):
    """
    ì‹ í˜¸ ì˜ˆì¸¡ í•¨ìˆ˜
    :param model: í•™ìŠµëœ ëª¨ë¸ ê°ì²´
    :param input_data: ì…ë ¥ ë°ì´í„°
    :return: ì˜ˆì¸¡ëœ ì‹ í˜¸
    """
    prediction = model.predict(input_data)
    return prediction
3ï¸âƒ£ evaluators.py
ëª©ì 
í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€.
ì£¼ìš” ê¸°ëŠ¥
ë‹¤ì–‘í•œ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°.
í‰ê°€ ê²°ê³¼ ì‹œê°í™”.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def evaluate_model(model, test_data):
    """
    ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ í•¨ìˆ˜
    :param model: í•™ìŠµëœ ëª¨ë¸
    :param test_data: í…ŒìŠ¤íŠ¸ ë°ì´í„°
    :return: ì„±ëŠ¥ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    from sklearn.metrics import classification_report
    predictions = model.predict(test_data["features"])
    return classification_report(test_data["labels"], predictions)
4ï¸âƒ£ arbitrage_trainer.py
ëª©ì 
ì•„ë¹„íŠ¸ë¼ì§€ ì „ëµ í•™ìŠµ ëª¨ë¸ êµ¬í˜„.
ì£¼ìš” ê¸°ëŠ¥
ê±°ë˜ì†Œ ê°„ ê°€ê²© ì°¨ì´ í•™ìŠµ.
ìµœì í™”ëœ ì•„ë¹„íŠ¸ë¼ì§€ ì „ëµ ìƒì„±.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def train_arbitrage_model(data):
    """
    ì•„ë¹„íŠ¸ë¼ì§€ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
    :param data: í•™ìŠµ ë°ì´í„°
    :return: í•™ìŠµëœ ì•„ë¹„íŠ¸ë¼ì§€ ëª¨ë¸
    """
    # ì•„ë¹„íŠ¸ë¼ì§€ ëª¨ë¸ í•™ìŠµ ë¡œì§ êµ¬í˜„
    pass
5ï¸âƒ£ rl_trainer.py
ëª©ì 
ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ í•™ìŠµ.
ì£¼ìš” ê¸°ëŠ¥
PPO, DDPG ë“±ì˜ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„.
í•™ìŠµëœ ì •ì±… ëª¨ë¸ ë°˜í™˜.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def train_rl_model(env, agent, episodes):
    """
    ê°•í™”í•™ìŠµ ëª¨ë¸ í•™ìŠµ
    :param env: ê°•í™”í•™ìŠµ í™˜ê²½
    :param agent: ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸
    :param episodes: í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜
    :return: í•™ìŠµëœ ëª¨ë¸
    """
    for episode in range(episodes):
        state = env.reset()
        done = False
        while not done:
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            agent.learn(state, action, reward, next_state, done)
            state = next_state
    return agent
6ï¸âƒ£ auto_update.py
ëª©ì 
ì§€ì†ì ì¸ í•™ìŠµ ë° ëª¨ë¸ ì—…ë°ì´íŠ¸.
ì£¼ìš” ê¸°ëŠ¥
ìµœì‹  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸.
ê¸°ì¡´ ëª¨ë¸ì— ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„°ë¥¼ ë°˜ì˜.
7ï¸âƒ£ model_storage.py
ëª©ì 
ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ.
ì£¼ìš” ê¸°ëŠ¥
í•™ìŠµëœ ëª¨ë¸ ì €ì¥.
ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°.
ì£¼ìš” í•¨ìˆ˜
python
ë³µì‚¬
í¸ì§‘
def save_model(model, path):
    """
    ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
    :param model: í•™ìŠµëœ ëª¨ë¸
    :param path: ì €ì¥ ê²½ë¡œ
    """
    import joblib
    joblib.dump(model, path)

def load_model(path):
    """
    ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
    :param path: ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ
    :return: ëª¨ë¸ ê°ì²´
    """
    import joblib
    return joblib.load(path)
```

--- 

## ğŸ”— í†µì‹  êµ¬ì¡° ë° ì˜ì¡´ì„±
```
preprocessor.py â†’ models/trainer.py â†’ models/rl_trainer.py â†’ models/inference.py â†’ signals/generator.py
```
ì£¼ìš” ì˜ì¡´ì„±
1. ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬:
   - scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬ ë° ì„±ëŠ¥ í‰ê°€.
   - xgboost: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ.
   - TensorFlow/Keras: ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬í˜„.
2. ë‚´ë¶€ ëª¨ë“ˆ:
signals/generator.py: ì‹ í˜¸ ìƒì„± ëª¨ë“ˆ.
utils/logger.py: í•™ìŠµ ë¡œê·¸ ê¸°ë¡.

---

## ğŸ“˜ ì°¸ê³  ë¬¸ì„œ ë° ë§í¬
1. ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
   - scikit-learn Documentation
   - TensorFlow Documentation
   - XGBoost Documentation
2. ë‚´ë¶€ ëª¨ë“ˆ
   - [Docs/Plan/Phase5/module_signals.md](Docs/Plan/Phase5/module_signals.md)
   - [Docs/Plan/Phase5/module_logger.md](Docs/Plan/Phase5/module_logger.md)
